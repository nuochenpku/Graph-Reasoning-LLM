{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, Dict, Sequence, List\n",
    "# import argparse\n",
    "\n",
    "def extract_last_num(text: str) -> float:\n",
    "    text = re.sub(r\"(\\d),(\\d)\", \"\\g<1>\\g<2>\", text)  # 处理形如 123,456\n",
    "    res = re.findall(r\"(\\d+(\\.\\d+)?)\", text)  # 匹配 123456.789\n",
    "    if len(res) > 0:\n",
    "        num_str = res[-1][0]\n",
    "        return float(num_str)\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def check(key, truth, predict):\n",
    "    if key in ['cycle', 'connectivity', 'hamilton', 'substructure', 'bipartite']:\n",
    "        if '###' in predict:\n",
    "            if 'yes' in truth.lower() and 'yes' in predict.split('###')[-1].lower():\n",
    "                # correct_samples[key].append(v)\n",
    "                return True\n",
    "            elif 'no' in truth.lower() and 'no' in predict.split('###')[-1].lower():\n",
    "                return True\n",
    "            return False\n",
    "        else:\n",
    "            matches = re.findall(r'(yes|no)', predict, flags=re.IGNORECASE)\n",
    "            if matches:\n",
    "                last_match = matches[-1].lower()\n",
    "                if last_match == 'yes' and 'yes' in truth.lower():\n",
    "                    return True\n",
    "                elif last_match == 'no' and 'no' in truth.lower():\n",
    "                    return True\n",
    "                return False\n",
    "            else:\n",
    "                return False\n",
    "                      \n",
    "    elif key in ['flow', 'shortest', 'triplet']:\n",
    "      \n",
    "        t_num = extract_last_num(truth)\n",
    "        p_num = extract_last_num(predict.split('###')[-1])\n",
    "        if abs(t_num - p_num) < 1e-2:\n",
    "            return True\n",
    "        return False\n",
    "                \n",
    "    elif key == 'topology':\n",
    "        \n",
    "        if '###' in predict:\n",
    "            pre = predict.split('###')[-1].strip(' ')\n",
    "            truth = truth.split('###')[-1].strip(' ')\n",
    "            if truth in pre or pre in truth:\n",
    "                return True\n",
    "            return False\n",
    "        else:\n",
    "            truth = truth.split('###')[-1].split(',')\n",
    "            for t in truth:\n",
    "                if t in predict or t.strip(' ') in predict:\n",
    "                    return True\n",
    "            return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67324\n"
     ]
    }
   ],
   "source": [
    "with open('/cpfs/user/chennuo/CN/Graph_RFT_Data/gpt4data/gpt4_gsm8knlg_sample3_output.json') as f:\n",
    "    datas = f.readlines()\n",
    "print(len(datas))\n",
    "\n",
    "tasks = ['cycle', 'connectivity', 'hamilton', 'substructure', 'bipartite', 'flow', 'shortest', 'triplet', 'topology']\n",
    "correct_samples  = {task:[] for task in tasks}\n",
    "all_samples  = {task:[] for task in tasks}\n",
    "temp = 0\n",
    "select_samples = []\n",
    "math_samples = []\n",
    "for data in datas:\n",
    "    \n",
    "    data = json.loads(data)\n",
    "        \n",
    "    task = data['task']\n",
    "    \n",
    "    if task in ['4','5', '6', '7', '8','9']:\n",
    "        temp += 1\n",
    "        math_samples.append(data)\n",
    "        continue\n",
    "    if check(task, data['response'], data['dv3_response']):\n",
    "        if data['query'] not in  correct_samples[task]:\n",
    "            correct_samples[task].append(data['query'])\n",
    "            select_samples.append(data)\n",
    "            \n",
    "    if data['query'] not in all_samples[task]:\n",
    "        all_samples[task].append(data['query'])\n",
    "        \n",
    "# with open('/cpfs/user/chennuo/CN/Graph_RFT_Data/gpt4data/gpt4_generate_nlg.json', 'w' ) as writer:\n",
    "#     for sample in select_samples:\n",
    "#         writer.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "\n",
    "\n",
    "# with open('/cpfs/user/chennuo/CN/Graph_RFT_Data/gpt4data/gpt4_generate_math.json', 'w' ) as writer:\n",
    "#     for sample in math_samples:\n",
    "#         writer.write(json.dumps(sample, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "3000\n",
      "connectivity\n",
      "3000\n",
      "hamilton\n",
      "3000\n",
      "substructure\n",
      "1130\n",
      "bipartite\n",
      "2991\n",
      "flow\n",
      "3000\n",
      "shortest\n",
      "2999\n",
      "triplet\n",
      "3000\n",
      "topology\n",
      "2973\n"
     ]
    }
   ],
   "source": [
    "for key, value in all_samples.items():\n",
    "    print(key)\n",
    "    print(len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16127"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(select_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle\n",
      "0.938\n",
      "connectivity\n",
      "0.9086666666666666\n",
      "hamilton\n",
      "0.7383333333333333\n",
      "substructure\n",
      "0.827433628318584\n",
      "bipartite\n",
      "0.675025075225677\n",
      "flow\n",
      "0.07533333333333334\n",
      "shortest\n",
      "0.49783261087029007\n",
      "triplet\n",
      "0.9186666666666666\n",
      "topology\n",
      "0.30507904473595693\n"
     ]
    }
   ],
   "source": [
    "for key, value in correct_samples.items():\n",
    "    print(key)\n",
    "    total = all_samples[key]\n",
    "    print(len(value)/len(total))\n",
    "\n",
    "# all_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Find the maximum sum of the weights of three interconnected nodes. In an undirected graph, [i, k] means that node i has the weight k. (i,j) means that node i and node j are connected with an undirected edge. Given a graph, you need to output the maximum sum of the weights of three interconnected nodes. \\nQ: The nodes are numbered from 0 to 13, weights of nodes are: [0, 1] [1, 5] [2, 6] [3, 10] [4, 8] [5, 3] [6, 10] [7, 5] [8, 3] [9, 6] [10, 9] [11, 9] [12, 7] [13, 6], and the edges are: (1, 7) (1, 3) (3, 7) (4, 5) (8, 9). What is the maximum sum of the weights of three nodes?'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_samples['triplet'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import json\n",
    "with open('/cpfs/user/chennuo/CN/Graph_RFT_Data/gpt4data/gpt4_generate_nlg.json') as f:\n",
    "    datas = f.readlines()\n",
    "refine_datas = []\n",
    "temp = 0\n",
    "for data in datas:\n",
    "    data = json.loads(data)\n",
    "    new_data = dict()\n",
    "    new_data['query'] = data['query']\n",
    "    new_data['task'] = data['task']\n",
    "    new_data['response'] = data['response']\n",
    "    response = data['dv3_response'].split('A:')[-1].split('\\n\\n')[-1]\n",
    "    if '###' not in response:\n",
    "        response +=  data['response'] +'.'\n",
    "    if 'print' in response or 'return' in response or 'def' in response:\n",
    "        temp += 1\n",
    "        continue\n",
    "    new_data['CoT_response'] = response\n",
    "    refine_datas.append(new_data)\n",
    "\n",
    "with open('/cpfs/user/chennuo/CN/Graph_RFT_Data/gpt4data/graph_source_data_v1.json', 'w' ) as writer:\n",
    "    for sample in refine_datas:\n",
    "        writer.write(json.dumps(sample, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Determine whether or not a graph is bipartite. In a directed graph, (i->j) means that node i and node j are connected with an directed edge from node i to node j. Given a graph, you need to output Yes or No, indicating whether the graph is bipartite. \\nQ: The nodes are numbered from 0 to 5, and the edges are: (0->2) (0->1) (1->2) (1->5) (2->5) (3->4) (4->5). Is this graph bipartite?',\n",
       " 'task': 'bipartite',\n",
       " 'response': '### No',\n",
       " 'CoT_response': \"Let us try this method on the given graph. We can start with node 0 and assign it to set A. Then, we assign its neighbors, node 1 and node 2, to set B. Next, we assign node 1's neighbors, node 5, to set A, and node 2's neighbor, node 5, to set A as well. \\nSo far, we have not encountered any contradiction, and we have assigned nodes 0, 1, 2, and 5 to different sets. \\nNow, we move on to node 3, which has not been assigned yet. We can assign it to either set, but let us choose set A for convenience. Then, we assign its neighbor, node 4, to set B. Finally, we assign node 4's neighbor, node 5, to set A. \\nHowever, this causes a contradiction, because node 5 is already in set A, and node 4 and node 5 have a direct edge between them. This means that we cannot assign all the nodes to two sets without violating the bipartite condition. \\nTherefore, the graph is not bipartite. ### No.\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(refine_datas, 10)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"Below is an instruction that describes a task. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "with open('/cpfs/user/chennuo/CN/Graph-Reasoning-LLM/datasets/data/graph_v1_dsformat.json', 'w' ) as writer:\n",
    "    for sample in refine_datas:\n",
    "        new_sample = dict()\n",
    "        new_sample['prompt'] = PROMPT_DICT[\"prompt_no_input\"].format(instruction=sample['query'])\n",
    "        new_sample['chosen'] = sample['CoT_response']\n",
    "        new_sample['reject'] = 'I do not know'\n",
    "        writer.write(json.dumps(new_sample, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"This is a sample string with YES and no, as well as YES.\"\n",
    "\n",
    "# Use regular expressions to find the last 'yes' or 'no' (case-insensitive)\n",
    "matches = re.findall(r'(yes|no)', text, flags=re.IGNORECASE)\n",
    "\n",
    "if matches:\n",
    "    last_match = matches[-1].lower()\n",
    "    if last_match == 'yes':\n",
    "        print('yes')\n",
    "    elif last_match == 'no':\n",
    "        print('no')\n",
    "else:\n",
    "    print(\"No 'yes' or 'no' found in the text.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Define the paths\n",
    "input_folder = '/cpfs/user/chennuo/CN/Graph-Reasoning-LLM/datasets/train_set'\n",
    "output_folder = '/cpfs/user/chennuo/CN/Graph-Reasoning-LLM/datasets/train_set_shuffle'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Get the list of JSON files in the input folder\n",
    "json_files = [file for file in os.listdir(input_folder) if file.endswith('.json')]\n",
    "\n",
    "# Iterate over each JSON file\n",
    "for file in json_files:\n",
    "    # Read the JSON file\n",
    "    with open(os.path.join(input_folder, file)) as f:\n",
    "        datas = f.readlines()\n",
    "    \n",
    "    data = [json.loads(item) for item in datas]\n",
    "    # Assign sample IDs\n",
    "    max_length = len(data)\n",
    "    for i, sample in enumerate(data):\n",
    "        sample['sample_id'] = i\n",
    "    \n",
    "    # Shuffle the samples\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    # Write the shuffled data to a new JSON file in the output folder\n",
    "    output_file = os.path.join(output_folder, file)\n",
    "    with open(output_file, 'w') as f:\n",
    "        # json.dump(data, f)\n",
    "        for new_sample in data:\n",
    "            f.write(json.dumps(new_sample, ensure_ascii=False) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
